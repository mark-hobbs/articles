{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "153ffb63-fa1f-4d9a-a8b0-cbc07a60512b",
      "metadata": {
        "id": "153ffb63-fa1f-4d9a-a8b0-cbc07a60512b"
      },
      "source": [
        "# Parallel reduction\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/mark-hobbs/articles/blob/main/cuda/parallel-reduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "See [this post](https://github.com/googlecolab/colabtools/issues/5081) to understand compatability issues with Google Colab and Numba CUDA\n",
        "\n",
        "Literature:\n",
        "- [Optimising parallel reduction in CUDA](https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd1b425f-3f99-4c2d-8c88-f60a784930e5",
      "metadata": {
        "id": "cd1b425f-3f99-4c2d-8c88-f60a784930e5"
      },
      "source": [
        "## Reduce bond forces to particle forces\n",
        "\n",
        "Bond forces can be stored as a bondlist or neighbour list\n",
        "\n",
        "- bondlist [n_bonds, 2]\n",
        "- neighbourlist [n_particles, n_family_members]\n",
        "\n",
        "Reduce:\n",
        "- particles.forces [n_particles, 1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install -q --system numba-cuda==0.13.0\n",
        "\n",
        "from numba import config\n",
        "config.CUDA_ENABLE_PYNVJITLINK = 1"
      ],
      "metadata": {
        "id": "aRl4unFhT3nE"
      },
      "id": "aRl4unFhT3nE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0edfd766-e9df-4e97-8632-19e5b1ad433a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0edfd766-e9df-4e97-8632-19e5b1ad433a",
        "outputId": "d25df460-2b70-4449-c053-4fbd954a9645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'articles'...\n",
            "remote: Enumerating objects: 547, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 547 (delta 38), reused 44 (delta 9), pack-reused 464 (from 1)\u001b[K\n",
            "Receiving objects: 100% (547/547), 101.07 MiB | 25.13 MiB/s, done.\n",
            "Resolving deltas: 100% (252/252), done.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numba import njit, prange\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    !git clone https://github.com/mark-hobbs/articles.git\n",
        "    import os\n",
        "    os.chdir('articles/cuda')  # Navigate to the cuda subdirectory\n",
        "except ImportError:\n",
        "    pass  # Already local, no need to clone\n",
        "\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "35899922-5ebf-4930-921d-4460e36c3286",
      "metadata": {
        "id": "35899922-5ebf-4930-921d-4460e36c3286"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "n_particles = 1500000\n",
        "n_family_members = 128\n",
        "\n",
        "bond_forces = np.random.rand(n_particles, n_family_members)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b4138f7-44d0-4a81-9d4a-1add7822b4f6",
      "metadata": {
        "id": "0b4138f7-44d0-4a81-9d4a-1add7822b4f6"
      },
      "source": [
        "### Numpy and Numba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "782a0d56-cfd3-4d51-98f1-5566c943cdb8",
      "metadata": {
        "id": "782a0d56-cfd3-4d51-98f1-5566c943cdb8"
      },
      "outputs": [],
      "source": [
        "@utils.profile(runs=10)\n",
        "def reduce_bond_forces_a(bond_forces):\n",
        "    n_particles = bond_forces.shape[0]\n",
        "    f = np.zeros((n_particles))\n",
        "    for i in range(n_particles):\n",
        "        f[i] = np.sum(bond_forces[i, :])\n",
        "    return f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b6d2f151-f9c4-4afb-9c9c-678c3e136ad0",
      "metadata": {
        "id": "b6d2f151-f9c4-4afb-9c9c-678c3e136ad0"
      },
      "outputs": [],
      "source": [
        "@utils.profile(runs=10)\n",
        "def reduce_bond_forces_b(bond_forces):\n",
        "    return np.sum(bond_forces, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "25f1cec9-a860-44a3-99a2-c8a74d74b6d6",
      "metadata": {
        "id": "25f1cec9-a860-44a3-99a2-c8a74d74b6d6"
      },
      "outputs": [],
      "source": [
        "@utils.profile(runs=10)\n",
        "@njit(parallel=True, fastmath=True)\n",
        "def reduce_bond_forces_c(bond_forces):\n",
        "    n_particles = bond_forces.shape[0]\n",
        "    f = np.zeros((n_particles))\n",
        "    for i in prange(n_particles):\n",
        "        f[i] = np.sum(bond_forces[i, :])\n",
        "    return f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "131c4a64-9cd1-426d-811d-791b9f78f8f0",
      "metadata": {
        "id": "131c4a64-9cd1-426d-811d-791b9f78f8f0",
        "outputId": "3c768bd2-7588-4b8c-e763-1bc03edfb6a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function 'reduce_bond_forces_a' executed 10 time(s)\n",
            "Average execution time: 5.0530 seconds\n",
            "Min: 4.9617s, Max: 5.1249s\n",
            "\n",
            "Function 'reduce_bond_forces_b' executed 10 time(s)\n",
            "Average execution time: 0.1271 seconds\n",
            "Min: 0.1266s, Max: 0.1289s\n",
            "\n",
            "Function 'reduce_bond_forces_c' executed 10 time(s)\n",
            "Average execution time: 0.2069 seconds\n",
            "Min: 0.0216s, Max: 1.8722s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "f_a = reduce_bond_forces_a(bond_forces)\n",
        "f_b = reduce_bond_forces_b(bond_forces)\n",
        "f_c = reduce_bond_forces_c(bond_forces)\n",
        "assert np.allclose(f_a, f_b) and np.allclose(f_b, f_c), \"Results are not equal\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd28085-164b-40d9-b9a2-07f606cc70f3",
      "metadata": {
        "id": "9fd28085-164b-40d9-b9a2-07f606cc70f3"
      },
      "source": [
        "### Numba CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d56ea9fb-4d75-4cfa-9d73-7aa4613452de",
      "metadata": {
        "id": "d56ea9fb-4d75-4cfa-9d73-7aa4613452de"
      },
      "outputs": [],
      "source": [
        "from numba import cuda, float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1fc752a6-a24f-45e5-bf65-405334955c25",
      "metadata": {
        "id": "1fc752a6-a24f-45e5-bf65-405334955c25"
      },
      "outputs": [],
      "source": [
        "THREADS_PER_BLOCK = 256\n",
        "\n",
        "@cuda.jit\n",
        "def reduce_bond_forces_kernel(bond_forces, particle_forces):\n",
        "    \"\"\"\n",
        "    Reduce bond forces to particle forces\n",
        "\n",
        "    Employ sequential addressing\n",
        "    \"\"\"\n",
        "\n",
        "    shared = cuda.shared.array(THREADS_PER_BLOCK, dtype=bond_forces.dtype)\n",
        "\n",
        "    particle = cuda.blockIdx.x\n",
        "    tid = cuda.threadIdx.x\n",
        "    n_family_members = bond_forces.shape[1]\n",
        "\n",
        "    # Initialise shared memory\n",
        "    val = 0.0\n",
        "    if tid < n_family_members:\n",
        "        val = bond_forces[particle, tid]\n",
        "    shared[tid] = val\n",
        "\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    stride = THREADS_PER_BLOCK // 2\n",
        "    while stride > 0:\n",
        "        if tid < stride:\n",
        "            shared[tid] += shared[tid + stride]\n",
        "        cuda.syncthreads()\n",
        "        stride //= 2\n",
        "\n",
        "    if tid == 0:\n",
        "        particle_forces[particle] = shared[0]\n",
        "\n",
        "@utils.profile(runs=10)\n",
        "def reduce_bond_forces_gpu(bond_forces):\n",
        "    n_particles, n_family_members = bond_forces.shape\n",
        "\n",
        "    bond_forces = cuda.to_device(bond_forces.astype(np.float32))\n",
        "    f = cuda.device_array(n_particles, dtype=np.float32)\n",
        "\n",
        "    reduce_bond_forces_kernel[n_particles, THREADS_PER_BLOCK](bond_forces, f)\n",
        "    return f.copy_to_host()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cc9f08a1-cf9f-48a3-a62b-aa42eb14836e",
      "metadata": {
        "id": "cc9f08a1-cf9f-48a3-a62b-aa42eb14836e",
        "outputId": "409219d9-7c72-47c0-a047-d7a097164ddd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Device Information:\n",
            "----------------------------------------\n",
            "CUDA Runtime Version:          12.5\n",
            "Device Name:                   b'NVIDIA L4'\n",
            "Compute Capability:            (8, 9)\n",
            "\n",
            "Memory:\n",
            "Total Memory:                  23.80 GB\n",
            "Free Memory:                   23.60 GB\n",
            "\n",
            "Compute Resources:\n",
            "Streaming Multiprocessors:     58\n",
            "Max Threads per Block:         1024\n",
            "\n",
            "Grid Limitations:\n",
            "Max Grid Dimensions X:         2147483647\n",
            "Max Grid Dimensions Y:         65535\n",
            "Max Grid Dimensions Z:         65535\n",
            "\n",
            "Additional Characteristics:\n",
            "Warp Size:                     32\n",
            "Clock Rate:                    2.04 GHz\n",
            "Memory Clock Rate:             6.25 GHz\n"
          ]
        }
      ],
      "source": [
        "utils.get_cuda_device_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0ec3189a-d455-4489-baaf-ea388669f8db",
      "metadata": {
        "id": "0ec3189a-d455-4489-baaf-ea388669f8db",
        "outputId": "72ba814a-9d2c-4dfc-e5fd-5cd0d1be4b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "declare_device_function() got an unexpected keyword argument 'use_cooperative'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2031332188.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_bond_forces_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbond_forces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Results are not equal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/articles/cuda/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3234271802.py\u001b[0m in \u001b[0;36mreduce_bond_forces_gpu\u001b[0;34m(bond_forces)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mreduce_bond_forces_kernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTHREADS_PER_BLOCK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbond_forces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         return self.dispatcher.call(\n\u001b[0m\u001b[1;32m    684\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msharedmem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverloads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharedmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof_pyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtypeof_pyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba/core/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Compilation disabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargetoptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;31m# We call bind to force codegen, so that there is a cubin to cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m             \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba/core/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, py_func, argtypes, link, debug, lineinfo, inline, forceinline, fastmath, extensions, max_registers, lto, opt, device)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_current_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_capability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         cres = compile_cuda(\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba/core/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/compiler.py\u001b[0m in \u001b[0;36mcompile_cuda\u001b[0;34m(pyfunc, return_type, args, debug, lineinfo, forceinline, fastmath, nvvm_options, cc, max_registers, lto)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtarget_override\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         cres = compiler.compile_extra(\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0mtypingctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtypingctx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mtargetctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargetctx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     \"\"\"\n\u001b[0;32m--> 742\u001b[0;31m     pipeline = pipeline_class(typingctx, targetctx, library,\n\u001b[0m\u001b[1;32m    743\u001b[0m                               args, return_type, flags, locals)\n\u001b[1;32m    744\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, typingctx, targetctx, library, args, return_type, flags, locals)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;31m# Make sure the environment is reloaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mtypingctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mtargetctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba/core/typing/context.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mUseful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthird\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mparty\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \"\"\"\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_additional_registries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;31m# Some extensions may have augmented the builtin registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_builtins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/target.py\u001b[0m in \u001b[0;36mload_additional_registries\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCUDATypingContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_additional_registries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcudadecl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcudamath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibdevicedecl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menumdecl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcffi_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadecl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m \u001b[0mhsin_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_resolve_wrapped_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hsin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0mhcos_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_resolve_wrapped_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hcos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0mhlog_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_resolve_wrapped_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hlog\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadecl.py\u001b[0m in \u001b[0;36m_resolve_wrapped_unary\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_resolve_wrapped_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m     decl = declare_device_function(\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;34mf\"__numba_wrapper_{fname}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: declare_device_function() got an unexpected keyword argument 'use_cooperative'"
          ]
        }
      ],
      "source": [
        "f_gpu = reduce_bond_forces_gpu(bond_forces)\n",
        "assert np.allclose(f_a, f_gpu), \"Results are not equal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w0xZX45xzS6L",
      "metadata": {
        "id": "w0xZX45xzS6L"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def benchmark_kernel(bond_forces, num_runs=100):\n",
        "    n_particles, n_family_members = bond_forces.shape\n",
        "\n",
        "    bond_forces = cuda.to_device(bond_forces.astype(np.float32))\n",
        "    f = cuda.device_array(n_particles, dtype=np.float32)\n",
        "\n",
        "    # Warm up the kernel\n",
        "    for _ in range(5):\n",
        "        reduce_bond_forces_kernel[n_particles, THREADS_PER_BLOCK](bond_forces, f)\n",
        "\n",
        "    cuda.synchronize()\n",
        "\n",
        "    start = time.perf_counter()\n",
        "\n",
        "    for _ in range(num_runs):\n",
        "        reduce_bond_forces_kernel[n_particles, THREADS_PER_BLOCK](bond_forces, f)\n",
        "\n",
        "    cuda.synchronize()\n",
        "\n",
        "    end = time.perf_counter()\n",
        "\n",
        "    avg = (end - start) / num_runs\n",
        "    return avg, f.copy_to_host()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2uyMwMy6zYNR",
      "metadata": {
        "id": "2uyMwMy6zYNR"
      },
      "outputs": [],
      "source": [
        "cuda_event_time, result = benchmark_kernel(bond_forces, num_runs=100)\n",
        "print(f\"Kernel executed in {cuda_event_time:.4f} seconds\")\n",
        "assert np.allclose(f_a, result), \"Results are not equal\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab2ed940-69eb-4378-9784-20408ee98ffb",
      "metadata": {
        "id": "ab2ed940-69eb-4378-9784-20408ee98ffb"
      },
      "source": [
        "## First add during load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f0c042a-25fd-4f37-bfa9-261252ba0f1d",
      "metadata": {
        "id": "3f0c042a-25fd-4f37-bfa9-261252ba0f1d"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def reduce_bond_forces_kernel(bond_forces, particle_forces):\n",
        "    \"\"\"\n",
        "    Reduce bond forces to particle forces\n",
        "\n",
        "    Employ sequential addressing with optimised first add during load\n",
        "    \"\"\"\n",
        "\n",
        "    shared = cuda.shared.array(THREADS_PER_BLOCK, dtype=bond_forces.dtype)\n",
        "\n",
        "    particle = cuda.blockIdx.x\n",
        "    tid = cuda.threadIdx.x\n",
        "    n_family_members = bond_forces.shape[1]\n",
        "\n",
        "    val = 0.0\n",
        "    if tid < n_family_members:\n",
        "        val += bond_forces[particle, tid]\n",
        "\n",
        "    if tid + THREADS_PER_BLOCK // 2 < n_family_members:\n",
        "        val += bond_forces[particle, tid + THREADS_PER_BLOCK // 2]\n",
        "\n",
        "    shared[tid] = val\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    stride = THREADS_PER_BLOCK // 4  # Start with quarter instead of half\n",
        "    while stride > 0:\n",
        "        if tid < stride:\n",
        "            shared[tid] += shared[tid + stride]\n",
        "        cuda.syncthreads()\n",
        "        stride //= 2\n",
        "\n",
        "    if tid == 0:\n",
        "        particle_forces[particle] = shared[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a05934-8bf8-4d26-8fc3-73007f34b294",
      "metadata": {
        "id": "00a05934-8bf8-4d26-8fc3-73007f34b294"
      },
      "outputs": [],
      "source": [
        "cuda_event_time, result = benchmark_kernel(bond_forces, num_runs=100)\n",
        "print(f\"Kernel executed in {cuda_event_time:.4f} seconds\")\n",
        "assert np.allclose(f_a, result), \"Results are not equal\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f_a, \"\\n\", result)"
      ],
      "metadata": {
        "id": "fFBbYvkapCf0"
      },
      "id": "fFBbYvkapCf0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}